
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2.2.2. Hồi qui Ridge &#8212; Deep AI KhanhBlog</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/RidgedRegression.html" />
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Bài toán phân loại" href="index_classification.html" />
    <link rel="prev" title="2.2. Hồi qui Ridge và Lasso" href="index_RidgedRegression.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/ML_course_logos.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep AI KhanhBlog</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html">
   Các chương dự kiến
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Mục tiêu cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html">
   Latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../grossary.html">
   Bảng thuật ngữ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/appendix_dtypes.html">
   1. Định dạng dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html">
     1.1. Các định dạng số, boolean và ký tự
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pandas.html">
   2. Pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html">
     2.1. Khởi tạo dataframe
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_numpy.html">
   3. Numpy
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html">
     3.1. Khởi tạo một mảng trên numpy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_matplotlib.html">
   4. Matplotlib
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html">
     4.1. Format chung của một biểu đồ trên matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_OOP.html">
   5. Lập trình hướng đối tượng (Object Oriented Programming - OOP)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html">
     5.1. Class và Object
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pipeline.html">
   6. Sklearn Pipeline
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html">
     6.1. Thiết kế pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_Convex_Opt.html">
   7. Giới thiệu chung về optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html">
     7.1. Bài toán dạng tổng quát
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đại số tuyến tính
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html">
   1. Đại số tuyến tính
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html">
   1. Giải tích tích phân
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Xác suất
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html">
   1. Xác suất
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index_MLIntroduce.html">
   1. Khái quát Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_prediction.html">
   2. Bài toán dự báo
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html">
     2.1. Ứng dụng của hồi qui tuyến tính
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index_RidgedRegression.html">
   2.2. Hồi qui Ridge và Lasso
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     2.2.2. Hồi qui Ridge
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_classification.html">
   3. Bài toán phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html">
     3.1. Hồi qui Logistic
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_OvfAndUdf.html">
   4. Độ chệch (
   <em>
    bias
   </em>
   ) và phương sai (
   <em>
    variance
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html">
     4.1. Sự đánh đổi giữa độ chệch và phương sai
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_ModelMetric.html">
   5. Thước đo mô hình phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html">
     5.1. Bộ dữ liệu
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_creditScorecard.html">
   6. Ứng dụng mô hình scorecard
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html">
     6.1. Phương pháp chuyên gia và mô hình
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_SVM.html">
   7. Giới thiệu về SVM
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html">
     7.1. Hàm mất mát của SVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_DecisionTree.html">
   8. Khái niệm về cây quyết định
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html">
     8.1. Mô hình cây quyết định (
     <em>
      decision tree
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_RandomForest.html">
   9. Giới thiệu về mô hình rừng cây (
   <em>
    Random Forest
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html">
     9.1. Ý tưởng của mô hình rừng cây
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Bayes.html">
   10. Bạn là
   <em>
    Tần suất
   </em>
   (
   <em>
    Frequentist
   </em>
   ) hay
   <em>
    Bayesian
   </em>
   ?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html">
     10.1. Ước lượng hợp lý tối đa (
     <em>
      Maximum Likelihood Function - MLE
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_FeatureEngineering.html">
   11. Giới thiệu về feature engineering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html">
     11.1. Feature Engineering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Boosting.html">
   12. Phương pháp tăng cường (
   <em>
    Boosting
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html">
     12.1. AdaBoosting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_KMeans.html">
   13. k-Means Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html">
     13.1. Các bước của thuật toán k-Means Clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_HierarchicalClustering.html">
   14. Hierarchical Clustering (
   <em>
    phân cụm phân cấp
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html">
     14.1. Chiến lược hợp nhất (
     <em>
      agglomerative
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_DBSCAN.html">
   15. DBSCAN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html">
     15.1. Phương pháp phân cụm dựa trên mật độ (
     <em>
      Density-Based Clustering
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_GMM.html">
   16. Gaussian Mixture Model
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="GMM.html">
     16.1. Ước lượng MLE cho
     <em>
      phân phối Gaussian đa chiều
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_PCA.html">
   17. Giảm chiều dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="PCA.html">
     17.1. Phương pháp phân tích suy biến
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đóng góp từ những tác giả khác
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/fubini_and_riemann.html">
   Tích phân Riemann và định lý Fubini
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/information_theory.html">
   Lý thuyết thông tin
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_ml/RidgedRegression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_ml/RidgedRegression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phamdinhkhanh/deepai-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/phamdinhkhanh/deepai-book/issues/new?title=Issue%20on%20page%20%2Fch_ml/RidgedRegression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/phamdinhkhanh/deepai-book/edit/main/book/ch_ml/RidgedRegression.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phamdinhkhanh/deepai-book/main?urlpath=tree/book/ch_ml/RidgedRegression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   2.2.2. Hồi qui Ridge
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tinh-tong-quat-cua-mo-hinh">
     2.2.2.1. Tính tổng quát của mô hình
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bai-toan-hoi-qui-tuyen-tinh">
     2.2.2.2. Bài toán hồi qui tuyến tính
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#su-thay-doi-cua-ham-mat-mat-trong-hoi-qui-ridge">
     2.2.2.3. Sự thay đổi của hàm mất mát trong hồi qui Ridge
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nghiem-toi-uu-cua-hoi-qui-ridge">
     2.2.2.4. Nghiệm tối ưu của hồi qui Ridge
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#su-dam-bao-loi-giai-cua-hoi-qui-ridge">
     2.2.2.5. Sự đảm bảo lời giải của hồi qui Ridge
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huan-luyen-hoi-qui-ridge">
     2.2.2.6. Huấn luyện hồi qui Ridge
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dieu-chuan-tikhokov">
     2.2.2.7. Điều chuẩn Tikhokov
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hoi-qui-lasso">
   2.2.3. Hồi qui Lasso
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bai-toan-hoi-qui-lasso">
     2.2.3.1. Bài toán hồi qui Lasso
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huan-luyen-mo-hinh-lasso">
     2.2.3.2. Huấn luyện mô hình Lasso
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vi-sao-hoi-qui-lasso-lai-la-hoi-qui-lua-chon-bien">
   2.2.4. Vì sao hồi qui Lasso lại là hồi qui lựa chọn biến
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#elastic-net">
   2.2.5. Elastic Net
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tuning-he-so-cho-mo-hinh-hoi-qui-ridge-lasso-va-elastic-net">
   2.2.6. Tuning hệ số cho mô hình hồi qui Ridge, Lasso và Elastic Net
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tong-ket">
   2.2.7. Tổng kết
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-tap">
   2.2.8. Bài tập
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tai-lieu-tham-khao">
   2.2.9. Tài liệu tham khảo
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="hoi-qui-ridge">
<h1>2.2.2. Hồi qui Ridge<a class="headerlink" href="#hoi-qui-ridge" title="Permalink to this headline">¶</a></h1>
<div class="section" id="tinh-tong-quat-cua-mo-hinh">
<h2>2.2.2.1. Tính tổng quát của mô hình<a class="headerlink" href="#tinh-tong-quat-cua-mo-hinh" title="Permalink to this headline">¶</a></h2>
<p>Một mục tiêu tiên quyết để có thể áp dụng được mô hình vào thực tiến đó là chúng ta cần giảm thiểu hiện tượng <em>quá khớp</em>. Để thực hiện được mục tiêu đó, mô hình được huấn luyện được kì vọng sẽ nắm bắt được <strong>qui luật tổng quát</strong> từ <em>tập huấn luyện</em> (<em>train dataset</em>) mà qui luật đó phải đúng trên những dữ liệu mới mà nó chưa được học. Thông thường tập dữ liệu mới đó được gọi là <em>tập kiểm tra</em> (<em>test dataset</em>). Đây là một tập dữ liệu độc lập được sử dụng để đánh giá mô hình.</p>
</div>
<div class="section" id="bai-toan-hoi-qui-tuyen-tinh">
<h2>2.2.2.2. Bài toán hồi qui tuyến tính<a class="headerlink" href="#bai-toan-hoi-qui-tuyen-tinh" title="Permalink to this headline">¶</a></h2>
<p>Giả định dữ liệu đầu vào bao gồm <span class="math notranslate nohighlight">\(N\)</span> quan sát là những cặp các biến đầu vào và biến mục tiêu <span class="math notranslate nohighlight">\((\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \dots, (\mathbf{x}_N, y_N)\)</span>. Quá trình hồi qui mô hình sẽ tìm kiếm một véc tơ hệ số ước lượng <span class="math notranslate nohighlight">\(\mathbf{w} = [w_0, w_1, \dots, w_p]\)</span> sao cho tối thiểu hoá <em>hàm mất mát</em> dạng MSE:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{w}) = \frac{1}{N} \sum_{i=1}^{N} (y_i - \mathbf{w}^{\intercal}\mathbf{x}_i) = \frac{1}{N}||\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}||_{2}^{2}\]</div>
<p>Nhắc lại một chút về khái niệm hàm mất mát. Trong các mô hình học có giám sát của machine learning, từ dữ liệu đầu vào, thông qua phương pháp học tập (<em>learning algorithm</em>), chúng ta sẽ đặt ra một hàm giả thuyết <span class="math notranslate nohighlight">\(h\)</span> (<em>hypothesis function</em>) mô tả mối quan hệ dữ liệu giữa biến đầu vào và biến mục tiêu.</p>
<p><img alt="" src="https://imgur.com/zGehpUr.png" /></p>
<p><strong>Hình 1:</strong> Source: <a class="reference external" href="https://www.youtube.com/watch?v=kHwlB_j7Hkc">Andrew Ng - Linear Regression With One Variable</a>. Từ một quan sát đầu vào <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>, sau khi đưa vào hàm gỉa thuyết <span class="math notranslate nohighlight">\(h\)</span> chúng ta thu được giá trị dự báo <span class="math notranslate nohighlight">\(\hat{y}\)</span> ở đầu ra. Chữ <span class="math notranslate nohighlight">\(h\)</span> của tên hàm thể hiện cho từ <em>hypothesis</em> có nghĩa là <em>giả thuyết</em>, đây là một khái niệm đã tồn tại lâu năm trong thống kê. Để mô hình càng chuẩn xác thì sai số giữa giá trị dự báo <span class="math notranslate nohighlight">\(\hat{y}\)</span> và ground truth <span class="math notranslate nohighlight">\(y\)</span> càng phải nhỏ. Vậy làm thế nào để đo lường được mức độ nhỏ của sai số giữa <span class="math notranslate nohighlight">\(\hat{y}\)</span> và <span class="math notranslate nohighlight">\(y\)</span>? Các thuật toán học có giám sát trong machine learning sẽ sử dụng hàm mất mát để lượng hoá sai số này.</p>
<p>Hàm mất mát cũng chính là mục tiêu tối ưu khi huấn luyện mô hình. Dữ liệu đầu vào <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> và <span class="math notranslate nohighlight">\(y\)</span> được xem như là cố định và biến số của bài toán tối ưu chính là các giá trị trong véc tơ <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>.</p>
<p>Giá trị hàm mất mát <em>MSE</em> chính là trung bình của tổng bình phương phần dư. Phần dư chính là chênh lệch giữa giá trị thực tế và giá trị dự báo. Tối thiểu hoá hàm mất mát nhằm mục đích làm cho giá trị dự báo ít chênh lệch so với giá trị thực tế, giá trị thực tế còn được gọi là ground truth. Trước khi huấn luyện mô hình chúng ta chưa thực sự biết véc tơ hệ số <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> là gì. Chúng ta chỉ có thể đặt ra một giả thuyết về dạng hàm dự báo (trong trường hợp này là phương trình dạng tuyến tính) và các hệ số hồi qui tương ứng. Chính vì vậy mục đích của tối thiểu hoá hàm mất mát là để tìm ra tham số <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> phù hợp nhất mô tả một cách khái quát quan hệ dữ liệu giữa biến đầu vào <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> với biến mục tiêu <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> trên tập huấn luyện.</p>
<p>Tuy nhiên mối quan hệ này nhiều khi không mô tả được qui luật khái quát của dữ liệu nên dẫn tới hiện tượng <em>quá khớp</em>. Một trong những nguyên nhân dẫn tới sự không khái quát của mô hình đó là do mô hình quá phức tạp. Mức độ phức tạp càng cao khi độ lớn của các hệ số trong mô hình hồi qui ở những bậc cao có xu hướng lớn như phân tích trong hình bên dưới:</p>
<p><img alt="" src="https://i.imgur.com/j3UqbJy.jpeg" /></p>
<p><strong>Hình 2:</strong> Hình thể hiện mức độ phức tạp của mô hình theo sự thay đổi của bậc. Phương trình có độ phức tạp lớn nhất là phương trình bậc 3: <span class="math notranslate nohighlight">\(y = w_0 + w_1 x + w_2 x^2 + w_3 x^3\)</span>. Trong chương trình THPT chúng ta biết rằng phương trình bậc 3 thông thường sẽ có 2 điểm uốn và độ phức tạp lớn hơn bậc hai chỉ có 1 điểm uốn. Khi <span class="math notranslate nohighlight">\(w_3 \rightarrow 0\)</span> thì phương trình bậc 3 hội tụ về phương trình bậc 2: <span class="math notranslate nohighlight">\(y = w_0 + w_1 x + w_2 x^2\)</span>, lúc này phương trình là một đường cong dạng parbol và có độ phức tạp giảm. Tiếp tục kiểm soát độ lớn để <span class="math notranslate nohighlight">\(w_2 \rightarrow 0\)</span> trong phương trình bậc 2 ta sẽ thu được một đường thẳng tuyến tính dạng <span class="math notranslate nohighlight">\(y = w_0 + w_1 x\)</span> có độ phức tạp thấp nhất.</p>
<p>Như vậy kiểm soát độ lớn của hệ số ước lượng, đặc biệt là với bậc cao, sẽ giúp giảm bớt mức độ phức tạp của mô hình và thông qua đó khắc phục hiện tượng <em>quá khớp</em>. Vậy làm cách nào để kiểm soát chúng, cùng tìm hiểu chương bên dưới.</p>
</div>
<div class="section" id="su-thay-doi-cua-ham-mat-mat-trong-hoi-qui-ridge">
<h2>2.2.2.3. Sự thay đổi của hàm mất mát trong hồi qui Ridge<a class="headerlink" href="#su-thay-doi-cua-ham-mat-mat-trong-hoi-qui-ridge" title="Permalink to this headline">¶</a></h2>
<p>Hàm mất mát trong hồi qui Ridge sẽ có sự thay đổi so với hồi qui tuyến tính đó là <em>thành phần điều chuẩn</em> (<em>regularization term</em>) được cộng thêm vào hàm mất mát như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray} \mathcal{L}(\mathbf{w}) &amp; = &amp; \frac{1}{N}||\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}||_{2}^{2} + \alpha ||\mathbf{w}||_2^2 \\
&amp; = &amp; \frac{1}{N}||\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}||_{2}^{2} + \underbrace{\alpha R(\mathbf{w})}_{\text{regularization term}}
\end{eqnarray}\end{split}\]</div>
<p>Trong phương trình trên thì <span class="math notranslate nohighlight">\(\alpha \geq 0\)</span>. <span class="math notranslate nohighlight">\(\frac{1}{N}||\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}||_{2}^{2}\)</span> chính là tổng bình phương phần dư và <span class="math notranslate nohighlight">\(\alpha ||\mathbf{w}||_2^2\)</span> đại diện cho <em>thành phần điều chuẩn</em>.</p>
<p>Bài toán tối ưu hàm mất mát của hồi qui <em>Ridge</em> về bản chất là tối ưu song song hai thành phần bao gồm tổng bình phương phần dư và <em>thành phần điều chuẩn</em>. Hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> có tác dụng điều chỉnh độ lớn của <em>thành phần điều chuẩn</em> tác động lên hàm mất mát.</p>
<ul class="simple">
<li><p>Trường hợp <span class="math notranslate nohighlight">\(\alpha = 0\)</span>, <em>thành phần điều chuẩn</em> bị tiêu giảm và chúng ta quay trở về bài toán hồi qui tuyến tính.</p></li>
<li><p>Trường hợp <span class="math notranslate nohighlight">\(\alpha\)</span> nhỏ thì vai trò của <em>thành phần điều chuẩn</em> trở nên ít quan trọng. Mức độ kiểm soát <em>quá khớp</em> của mô hình sẽ trở nên kém hơn.</p></li>
<li><p>Trường hợp <span class="math notranslate nohighlight">\(\alpha\)</span> lớn chúng ta muốn gia tăng mức độ kiểm soát lên độ lớn của các hệ số ước lượng và qua đó giảm bớt hiện tượng <em>qúa khớp</em>.</p></li>
</ul>
<p>Khi tăng dần hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> thì <em>hồi qui Ridge</em> sẽ có xu hướng thu hẹp hệ số ước lượng từ mô hình. Chúng ta sẽ thấy rõ thông qua ví dụ mẫu bên dưới.</p>
<p><strong>Import thư viện và đọc dữ liệu đầu vào</strong></p>
<p>Bộ dữ liệu đầu vào được sử dụng cho ví dụ này là diabetes. Thông tin về bộ dữ liệu này bạn đọc có thể tham khảo tại <a class="reference external" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset">sklearn diabetes dataset</a>.</p>
<p>Mục tiêu của mô hình là từ 10 biến đầu vào là những thông tin liên quan tới người bệnh bao gồm <code class="docutils literal notranslate"><span class="pre">age,</span> <span class="pre">sex,</span> <span class="pre">body</span> <span class="pre">mass</span> <span class="pre">index,</span> <span class="pre">average</span> <span class="pre">blood</span> <span class="pre">pressure</span></code> và 6 chỉ số  <code class="docutils literal notranslate"><span class="pre">blood</span> <span class="pre">serum</span></code>. Chúng ta sẽ dự báo biến mục tiêu là một thước đo định lượng sự tiến triển của bệnh sau 1 năm điều trị.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">()[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Thay đổi alphas từ 1 --&gt; 100</span>
<span class="n">n_alphas</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_alphas</span><span class="p">)</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Huấn luyện model khi alpha thay đổi.</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>

<span class="c1"># Hiển thị kết quả mô hình cho các hệ số alpha</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">coefs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;coefficient of features&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Ridge coefficients khi thay đổi hệ số alpha&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/RidgedRegression_5_0.png" src="../_images/RidgedRegression_5_0.png" />
</div>
</div>
<p><strong>Hình 3:</strong> Sự thay đổi của độ lớn các hệ số ước lượng (<em>coefficient of features</em>) theo hệ số điều chuẩn <span class="math notranslate nohighlight">\(\alpha\)</span>. Khi tăng dần độ lớn của <span class="math notranslate nohighlight">\(\alpha\)</span> thì độ lớn của hệ số ước lượng giảm dần.</p>
<p>Việc lựa chọn <span class="math notranslate nohighlight">\(\alpha\)</span> như thế nào để phù hợp là một vấn đề sẽ được bàn luận kĩ hơn ở chương bên dưới.</p>
<p>Ngoài ra bài toán tối ưu đối với <em>hàm hồi qui Ridge</em> tương đương với bài toán tối ưu với điều kiện ràng buộc về độ lớn của hàm mục tiêu:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray} \mathcal{L}(\mathbf{w}) &amp; = &amp; \frac{1}{N}\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2} \\
\text{subject } &amp; : &amp; \|\mathbf{w}\|_2^2 &lt; C, C &gt; 0
\end{eqnarray}\end{split}\]</div>
<p>Thật vậy, để giải bài toán trên thì chúng ta có thể giải bài toán đối ngẫu trên hàm <em>đối ngẫu Lagrange</em>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\hat{\mathbf{w}} &amp; = &amp; \arg \min_{\mathbf{w}} \text{Lagrange}(\mathbf{w}, b) \\
&amp; = &amp; \arg \min \frac{1}{N}\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2} + \alpha (\|\mathbf{w}\|_2^2 - C) \\
&amp; = &amp; \arg \min \frac{1}{N}\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2} + \alpha \|\mathbf{w}\|_2^2
\end{eqnarray}\end{split}\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span>.</p>
<p>Như vậy bài toán <em>đối ngẫu</em> quay trở về tối thiểu hoá hàm mất mát trong <em>hồi qui Ridge</em>.</p>
<p>Điều kiện ràng buộc <span class="math notranslate nohighlight">\(\| \mathbf{w} \|_2^2 &lt; C\)</span> cho thấy nghiệm tối ưu sẽ bị hạn chế về độ lớn. Trong không gian đa chiều thì điều kiện ràng buộc có miền xác định là một khối cầu có tâm là gốc toạ độ và bán kính <span class="math notranslate nohighlight">\(\sqrt{C}\)</span>. Đây chính là một cơ chế kiểm soát mà <em>thành phần điều chuẩn</em> đã áp đặt lên các biến đầu vào.</p>
</div>
<div class="section" id="nghiem-toi-uu-cua-hoi-qui-ridge">
<h2>2.2.2.4. Nghiệm tối ưu của hồi qui Ridge<a class="headerlink" href="#nghiem-toi-uu-cua-hoi-qui-ridge" title="Permalink to this headline">¶</a></h2>
<p>Giải bài toán tối ưu <em>hàm mục tiêu</em> của <em>hồi qui Ridge</em> theo đạo hàm bậc nhất của véc tơ <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\frac{\partial\mathcal{L}(\mathbf{w})}{\partial\mathbf{w}} &amp; = &amp; \frac{1}{N}\frac{\partial\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2}}{\partial\mathbf{w}} + \alpha \frac{\partial \|\mathbf{w}\|^2_2}{\partial \mathbf{w}} \\
&amp; = &amp; \frac{2}{N}\mathbf{\bar{X}}^{\intercal}(\mathbf{\bar{X}}\mathbf{w} - \mathbf{y}) + 2 \alpha \mathbf{w} \\
&amp; = &amp; \frac{2}{N} [(\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I}) \mathbf{w} - \bar{\mathbf{X}}^{\intercal}\mathbf{y}] \\
&amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Thật vậy, từ dòng 1 suy ra dòng 2 là vì theo công thức product-rule trong matrix caculus thì:</p>
<div class="math notranslate nohighlight">
\[\nabla_{\mathbf{w}}f({\mathbf{w}})^{\intercal}g(\mathbf{w}) = \nabla_{\mathbf{w}}(f) g + \nabla_{\mathbf{w}}(g) f\]</div>
<p>Khi <span class="math notranslate nohighlight">\(f=g\)</span> thì đạo hàm trở thành:</p>
<div class="math notranslate nohighlight">
\[\nabla_{\mathbf{w}}f({\mathbf{w}})^{\intercal}f(\mathbf{w}) = \nabla_{\mathbf{w}} \|f({\mathbf{w}})\|_2^{2} = 2\nabla_{\mathbf{w}}(f) f\]</div>
<p>Nếu thay  <span class="math notranslate nohighlight">\(f(\mathbf{w}) = g(\mathbf{w})= \bar{\mathbf{X}} \mathbf{w}-\mathbf{y}\)</span> ta suy ra:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{\partial\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2}}{\partial \mathbf{w}} &amp; = &amp; \frac{\partial(\bar{\mathbf{X}}\mathbf{w} - \mathbf{y})^{\intercal} (\bar{\mathbf{X}}\mathbf{w} - \mathbf{y})}{\partial \mathbf{w}} \\
&amp; = &amp; \frac{2 \partial(\bar{\mathbf{X}}\mathbf{w} - \mathbf{y})}{\partial \mathbf{w}} (\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}) \\
&amp; = &amp; 2\bar{\mathbf{X}}^{\intercal}(\bar{\mathbf{X}}\mathbf{w}-\mathbf{y})
\end{eqnarray}\end{split}\]</div>
<p>Tương tự ta cũng có:</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial \|\mathbf{w}\|_2^2}{\partial \mathbf{w}} = 2\mathbf{w}\]</div>
<p>Như vậy ta nhận thấy dòng 1 suy ra dòng 2 là hoàn toàn đúng.</p>
<p>Ở dòng thứ 3 chúng ta áp dụng thêm một tính chất <span class="math notranslate nohighlight">\(\mathbf{I}\mathbf{w} = \mathbf{w}\)</span> trong đó <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> là ma trận đơn vị.</p>
<p>Sau cùng nghiệm của đạo hàm bậc nhất trở thành:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{2}{N} [(\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I}) \mathbf{w} - \bar{\mathbf{X}}^{\intercal}\mathbf{y}] &amp; = &amp; 0 \\
(\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I}) \mathbf{w} &amp; = &amp; \bar{\mathbf{X}}^{\intercal}\mathbf{y} \\
\mathbf{w} &amp; = &amp; (\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I})^{-1}\bar{\mathbf{X}}^{\intercal}\mathbf{y}
\end{eqnarray}\end{split}\]</div>
<p>Thành phần <span class="math notranslate nohighlight">\(N\alpha \mathbf{I}\)</span> được thêm vào trong <span class="math notranslate nohighlight">\((\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I})^{-1}\)</span> đóng vai trò như một thành phần kiểm soát để giá trị của <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> nhỏ hơn so với ban đầu. Trên thực tế thành phần này chỉ tác động lên những phần tử thuộc đường chéo chính của ma trận và làm cho độ lớn của nghiệm giảm.</p>
<p>Ngoài ra ta còn chứng minh được rằng ma trận <span class="math notranslate nohighlight">\(\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I}\)</span> là một <em>ma trận không suy biến</em> nếu <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span>. Điều đó đảm bảo rằng mô hình <em>hồi qui Ridge</em> luôn tìm được nghiệm. Bạn đọc quan tâm tới toán có thể thấy chứng minh này ở mục bên dưới.</p>
</div>
<div class="section" id="su-dam-bao-loi-giai-cua-hoi-qui-ridge">
<h2>2.2.2.5. Sự đảm bảo lời giải của hồi qui Ridge<a class="headerlink" href="#su-dam-bao-loi-giai-cua-hoi-qui-ridge" title="Permalink to this headline">¶</a></h2>
<p>Trước tiên hãy cùng ôn lại một số khái niệm liên quan tới ma trận.</p>
<p><strong>Định nghĩa bán xác định dương:</strong> Ma trận số thực đối xứng <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> là <em>bán xác định dương</em> (<em>positive semi-definite</em>) nếu với mọi véc tơ <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^{d}\)</span> thì <span class="math notranslate nohighlight">\(\mathbf{x}^{\intercal}\mathbf{A}\mathbf{x} \geq 0\)</span>.</p>
<p>Một tính chất thú vị đó là nếu một ma trận <em>bán xác định dương</em> thì mọi trị riêng của chúng là những số không âm. Thật vậy, theo định nghĩa thì <span class="math notranslate nohighlight">\(\lambda\)</span> là <em>trị riêng</em> (<em>eigen-value</em>) của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> tương ứng với một <em>véc tơ riêng</em> (<em>eigen-vector</em>) <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> nếu thỏa mãn:</p>
<div class="math notranslate nohighlight">
\[\mathbf{A}\mathbf{x} = \lambda \mathbf{x}\]</div>
<div class="math notranslate nohighlight">
\[\rightarrow \mathbf{x}^{\intercal} \mathbf{A} \mathbf{x} = \lambda \mathbf{x}^{\intercal}\mathbf{x} = \lambda ||\mathbf{x}||_2^2\]</div>
<p>Mặc khác vế trái không âm do <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> là ma trận bán xác định dương. Do đó vế phải <span class="math notranslate nohighlight">\(\lambda ||\mathbf{x}||_2^2 \geq 0\)</span>, từ đó suy ra <span class="math notranslate nohighlight">\(\lambda \geq 0\)</span> do <span class="math notranslate nohighlight">\(||\mathbf{x}||_2^2 \geq 0\)</span>.</p>
<p>Để chứng minh hồi qui Ridge luôn tồn tại nghiệm chúng ta dựa vào ba tính chất lý.</p>
<p>1.- Ma trận <span class="math notranslate nohighlight">\(\mathbf{A} = \bar{\mathbf{X}}^{\intercal}\bar{\mathbf{X}}\)</span> là một ma trận thực đối xứng <em>bán xác định dương</em> (<em>positive semi-definite</em>).
Thật vậy:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^\intercal\mathbf{A}\mathbf{x} = \mathbf{x}^\intercal\bar{\mathbf{X}}^{\intercal}\bar{\mathbf{X}}\mathbf{x} = ||\mathbf{A}\mathbf{x}||_2^2 \geq 0, \forall \mathbf{x} \in \mathbb{R}^d\]</div>
<p>Từ đó suy ra <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> là ma trận <em>bán xác định dương</em>. Như vậy các <em>trị riêng</em> (<em>eigenvalues</em>) của nó là <span class="math notranslate nohighlight">\(\mu_1, \dots, \mu_N\)</span> không âm.</p>
<p>2.- Nếu <span class="math notranslate nohighlight">\(\mu\)</span> là trị riêng của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> vuông thì <span class="math notranslate nohighlight">\(\mu+\beta\)</span> là trị riêng của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}+\beta\mathbf{I}\)</span>.</p>
<p>Để chứng minh ta dựa vào khai triển:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\mathbf{A}\mathbf{x} &amp; = &amp; \mu \mathbf{x} \\
\leftrightarrow (\mathbf{A} + \beta\mathbf{I}) \mathbf{x}&amp; = &amp; \mu \mathbf{x}+\beta \underbrace{\mathbf{I}\mathbf{x}}_{\mathbf{x}} \\
\leftrightarrow (\mathbf{A} + \beta\mathbf{I}) \mathbf{x}&amp; = &amp; (\mu+\beta)\mathbf{x}
\end{eqnarray}\end{split}\]</div>
<p>Dòng cuối cùng suy ra <span class="math notranslate nohighlight">\(\mu+\beta\)</span> chính là trị riêng của ma trận <span class="math notranslate nohighlight">\(\mathbf{A} + \beta \mathbf{I}\)</span>.</p>
<p>3.- Định thức của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> bằng tích các trị riêng của <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>.</p>
<p>Giả sử  <span class="math notranslate nohighlight">\(\lambda_1, \dots, \lambda_d\)</span> là các trị riêng của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>. Khi đó định thức:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\det{(\mathbf{A} - \lambda \mathbf{I})} = \det{\left (\begin{bmatrix} 
a_{11}-\lambda &amp; a_{12} &amp; \dots &amp; a_{1d}\\ 
a_{21} &amp; a_{22}-\lambda &amp; \dots &amp; a_{2d}\\ 
\dots &amp; \dots &amp; \ddots &amp; \dots\\ 
a_{d1} &amp; a_{d2} &amp; \dots &amp; a_{dd}-\lambda
\end{bmatrix} \right )} = P_{d}(\lambda)\end{split}\]</div>
<p>là một đa thức bậc <span class="math notranslate nohighlight">\(d\)</span> của <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
<p>Mặc khác với mỗi trị riêng <span class="math notranslate nohighlight">\(\lambda_i\)</span> của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> thì tồn tại véc tơ riêng <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> khác 0 thỏa mãn:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\mathbf{A} \mathbf{x} &amp; = &amp; \lambda_i \mathbf{x} \\
\leftrightarrow (\mathbf{A}-\lambda_i \mathbf{I})\mathbf{x} &amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Như vậy các dòng của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}-\lambda_i \mathbf{I}\)</span> phụ thuộc tuyến tính theo véc tơ <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> nên <span class="math notranslate nohighlight">\(P_d(\lambda_i) = \det(\mathbf{A} - \lambda_i \mathbf{I}) = 0\)</span>. Từ đó suy ra <span class="math notranslate nohighlight">\(P_d(\lambda)\)</span> có <span class="math notranslate nohighlight">\(d\)</span> nghiệm là các trị riêng của ma trận <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>. Kết hợp với hệ số của bậc cao nhất <span class="math notranslate nohighlight">\(\lambda^d\)</span> là <span class="math notranslate nohighlight">\((-1)^d\)</span> ta suy ra:</p>
<div class="math notranslate nohighlight">
\[P_d(\lambda) = (-1)^d(\lambda - \lambda_1)(\lambda - \lambda_2) \dots (\lambda - \lambda_d) = 
(\lambda_1 - \lambda)(\lambda_2 - \lambda) \dots (\lambda_d - \lambda)\]</div>
<p>Do đó:</p>
<div class="math notranslate nohighlight">
\[\det(\mathbf{A}) = P_d(0) = \lambda_1 \lambda_2 \dots \lambda_d\]</div>
<p>Quay trở lại bài toán chứng minh <span class="math notranslate nohighlight">\((\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I})\)</span> là một ma trận không suy biến.</p>
<p>Giả định <span class="math notranslate nohighlight">\(\mu\)</span> là véc tơ trị riêng của ma trận <span class="math notranslate nohighlight">\(\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}}\)</span>. Như vậy từ tính chất 2 suy ra <em>trị riêng</em> của ma trận <span class="math notranslate nohighlight">\(\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I}\)</span> là <span class="math notranslate nohighlight">\(\lambda = \mu + N\alpha\)</span>.</p>
<p>Mặt khác theo tính chất 1 thì <span class="math notranslate nohighlight">\(\mu \geq 0\)</span> do <span class="math notranslate nohighlight">\(\bar{\mathbf{X}}^{\intercal}\bar{\mathbf{X}}\)</span> bán xác định dương. Từ đó suy ra <span class="math notranslate nohighlight">\(\lambda \geq N\alpha &gt; 0\)</span>. Như vậy ma trận <span class="math notranslate nohighlight">\((\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I})\)</span> có khác trị riêng khác 0. Theo tính chất 3 ta suy ra <span class="math notranslate nohighlight">\(\det{(\mathbf{A})} \neq 0\)</span> do các trị riêng đều khác 0. Như vậy <span class="math notranslate nohighlight">\((\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \mathbf{I})\)</span> là một ma trận không suy biến và <em>hồi qui Ridge</em> đảm bảo tồn tại nghiệm.</p>
</div>
<div class="section" id="huan-luyen-hoi-qui-ridge">
<h2>2.2.2.6. Huấn luyện hồi qui Ridge<a class="headerlink" href="#huan-luyen-hoi-qui-ridge" title="Permalink to this headline">¶</a></h2>
<p>Để huấn luyện mô hình hồi qui Ridge trên sklearn chúng ta sử dụng module <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.Ridge</span></code> như bên dưới. Đối số cần lưu ý chính là <code class="docutils literal notranslate"><span class="pre">alpha</span></code> tương ứng với hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> của <em>thành phần điều chuẩn</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reg_ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">reg_ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Sai số huấn luyện của mô hình trên tập train</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="c1"># Hệ số hồi qui và hệ số chặn</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_ridge</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.4062765748571143
[  40.22939469  -61.6891284   273.28923195  197.33160511   -1.61665406
  -19.12583524 -142.98129661  107.3757613   195.22498998   84.3326197 ]
150.9272009480016
</pre></div>
</div>
</div>
</div>
<p>Tối ưu hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> như thế nào sẽ được bàn luận ở chương 2.2.6.</p>
</div>
<div class="section" id="dieu-chuan-tikhokov">
<h2>2.2.2.7. Điều chuẩn Tikhokov<a class="headerlink" href="#dieu-chuan-tikhokov" title="Permalink to this headline">¶</a></h2>
<p>Khi xây dựng mô hình trên những bộ dữ liệu có số lượng lớn các biến đầu vào thì thường xuất hiện hiện tượng đa cộng tuyến khiến ước lượng từ mô hình bị chệch. Chúng ta có thể khắc phục hiện tượng này thông qua áp dụng thành phần điều chuẩn Tikhonov:</p>
<div class="math notranslate nohighlight">
\[\lambda R(\mathbf{w}) = \|\Gamma \mathbf{w} \|_2^2\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(\Gamma\)</span> là một ma trận vuông, thông thường được lựa chọn là một ma trận đường chéo.</p>
<p>Nếu giải bài toán tối ưu theo đạo hàm bậc nhất thì ta thu được nghiệm khi sử dụng điều chuẩn Tikhokov:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\frac{\partial\mathcal{L}(\mathbf{w})}{\partial\mathbf{w}} &amp; = &amp; \frac{1}{N}\frac{\partial\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2}}{\partial\mathbf{w}} + \alpha \frac{\partial \|\Gamma\mathbf{w}\|^2_2}{\partial \mathbf{w}} \\
&amp; = &amp; \frac{2}{N}\mathbf{\bar{X}}^{\intercal}(\mathbf{\bar{X}}\mathbf{w} - \mathbf{y}) + 2 \alpha \Gamma^{\intercal}\Gamma\mathbf{w} \\
&amp; = &amp; \frac{2}{N} [(\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \Gamma^{\intercal}\Gamma) \mathbf{w} - \bar{\mathbf{X}}^{\intercal}\mathbf{y}] \\
&amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Nghiệm tối ưu:</p>
<div class="math notranslate nohighlight">
\[\mathbf{w} = (\mathbf{\bar{X}}^{\intercal}\mathbf{\bar{X}} + N\alpha \Gamma^{\intercal}\Gamma)^{-1}\bar{\mathbf{X}}^{\intercal}\mathbf{y}\]</div>
<p>Nếu tính tế chúng ta sẽ nhận thấy <em>hồi qui Ridge</em> chính là một trường hợp đặc biểu của điều chuẩn Tikhokov khi lựa chọn <span class="math notranslate nohighlight">\(\Gamma = \alpha\mathbf{I}\)</span> trong đó <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> là ma trận đơn vị.</p>
<p>Trong mô hình hồi qui không phải khi nào thì vai trò của các biến đầu vào cũng đều quan trọng như nhau. Khi lựa chọn <span class="math notranslate nohighlight">\(\Gamma\)</span> là một ma trận đường chéo chúng ta thu được một phiên bản <em>weighted l2 regularization</em>. Độ lớn của các phần tử trên đường chéo sẽ ảnh hưởng tới mức độ kiểm soát được áp đặt lên biến. Nếu biến đầu vào <span class="math notranslate nohighlight">\(w_i\)</span> là nguyên nhân dẫn tới hiện tượng overfitting thì có thể thiết lập <span class="math notranslate nohighlight">\(\alpha_i\)</span> một giá trị lớn hơn so với những thành phần khác nằm trên đường chéo chính. Ngoài ra trong những phương trình hồi qui sử dụng <em>đặc trưng đa thức</em> (<em>polynomial feature</em>) thì chúng ta thường sẽ gán giá trị cao hơn cho trọng số của những biến bậc cao trong thành phần điều chuẩn để giảm thiểu <em>quá khớp</em>.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="hoi-qui-lasso">
<h1>2.2.3. Hồi qui Lasso<a class="headerlink" href="#hoi-qui-lasso" title="Permalink to this headline">¶</a></h1>
<div class="section" id="bai-toan-hoi-qui-lasso">
<h2>2.2.3.1. Bài toán hồi qui Lasso<a class="headerlink" href="#bai-toan-hoi-qui-lasso" title="Permalink to this headline">¶</a></h2>
<p>Trong hồi qui Lasso, thay vì sử dụng <em>thành phần điều chuẩn</em> là norm chuẩn bậc hai thì chúng ta sử dụng norm chuẩn bậc 1.</p>
<div class="math notranslate nohighlight">
\[\begin{eqnarray} \mathcal{L}(\mathbf{w}) &amp; = &amp; \frac{1}{N}\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2} + \underbrace{\alpha\|\mathbf{w}\|_1}_{\text{regularization term}}
\end{eqnarray}\]</div>
<p>Nếu bạn chưa biết về norm chuẩn bậc 1 thì có thể xem lại <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_algebra/appendix_algebra.html#khai-niem-chuan">khái niệm norm chuẩn</a>.</p>
<p>Khi tiến hành hồi qui mô hình <em>Lasso</em> trên một bộ dữ liệu mà có các biến đầu vào <em>đa cộng tuyến</em> (<em>multicollinear</em>) thì mô hình hồi qui Lasso sẽ có xu hướng lựa chọn ra một biến trong nhóm các biến đa cộng tuyến và bỏ qua những biến còn lại. Trong khi ở mô hình hồi qui tuyến tính thông thường và hồi qui Ridge thì có xu hướng sử dụng tất cả các biến đầu vào. Điều này sẽ được làm rõ hơn ở mục 2.2.4.</p>
<p>Bài toán tối ưu đối với <em>hàm hồi qui Lasso</em> tương đương với bài toán tối ưu với điều kiện ràng buộc về độ lớn của hàm mục tiêu:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray} \mathcal{L}(\mathbf{w}) &amp; = &amp; \frac{1}{N}\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2} + \alpha \|\mathbf{w}\|_1 \\
\text{subject } &amp; : &amp; \|\mathbf{w}\|_1 &lt; C, C &gt; 0
\end{eqnarray}\end{split}\]</div>
<p><em>Thành phần điều chuẩn</em> norm bậc 1 cũng có tác dụng như một sự kiểm soát áp đặt lên hệ số ước lượng. Khi muốn gia tăng sự kiểm soát, chúng ta sẽ gia tăng hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> để mô hình trở nên bớt phức tạp hơn. Cũng tương tự như <em>hồi qui Ridge</em> chúng ta cùng phân tích tác động của <span class="math notranslate nohighlight">\(\alpha\)</span>:</p>
<ul class="simple">
<li><p>Trường hợp <span class="math notranslate nohighlight">\(\alpha = 0\)</span>, <em>thành phần điều chuẩn</em> bị tiêu giảm và chúng ta quay trở về bài toán hồi qui tuyến tính.</p></li>
<li><p>Trường hợp <span class="math notranslate nohighlight">\(\alpha\)</span> nhỏ thì vai trò của <em>thành phần điều chuẩn</em> trở nên ít quan trọng. Mức độ kiểm soát <em>quá khớp</em> của mô hình sẽ trở nên kém hơn.</p></li>
<li><p>Trường hợp <span class="math notranslate nohighlight">\(\alpha\)</span> lớn chúng ta muốn gia tăng mức độ kiểm soát lên độ lớn của các hệ số ước lượng.</p></li>
</ul>
</div>
<div class="section" id="huan-luyen-mo-hinh-lasso">
<h2>2.2.3.2. Huấn luyện mô hình Lasso<a class="headerlink" href="#huan-luyen-mo-hinh-lasso" title="Permalink to this headline">¶</a></h2>
<p>Để huấn luyện mô hình hồi qui <em>Lasso</em> trên sklearn chúng ta sử dụng module <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.Lasso</span></code>. Chúng ta cần quan tâm tới thiết lập hệ số nhân <span class="math notranslate nohighlight">\(\alpha\)</span> của <em>thành phần điều chuẩn</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>

<span class="n">reg_lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">reg_lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Sai số huấn luyện trên tập train</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>

<span class="c1"># Hệ số hồi qui và hệ số chặn</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_lasso</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.34247555718513434
[  0.          -0.         425.89461957  69.18843585   0.
   0.          -0.           0.         177.77583411   0.        ]
150.97739174702443
</pre></div>
</div>
</div>
</div>
<p>Nếu muốn tuning hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> phù hợp nhất cho mô hình <em>hồi qui Lasso</em>, sklearn cung cấp một module hỗ trợ ta làm công việc này. Đó chính là <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.LassoCV</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">reg_lasso_cv</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_lasso_cv</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reg_lasso_cv</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-4.21242132e-01 -0.00000000e+00  8.74020196e+00  0.00000000e+00
 -0.00000000e+00  0.00000000e+00  5.04074761e-02  7.46065852e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -0.00000000e+00 -1.72366886e-01  0.00000000e+00 -0.00000000e+00
 -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -4.29663159e-01
  1.43615035e-01  0.00000000e+00 -1.79948525e-01  0.00000000e+00
 -0.00000000e+00  7.30847374e+01 -3.43884703e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.13286030e-01 -0.00000000e+00
  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00
 -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00
 -0.00000000e+00  3.94405369e+01 -0.00000000e+00 -0.00000000e+00
  5.23718682e+01  8.32674366e-01  4.35584487e+01 -0.00000000e+00
  0.00000000e+00  1.55124290e-01  2.58648431e-01 -0.00000000e+00
  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00
  3.22013861e+01  0.00000000e+00 -0.00000000e+00 -0.00000000e+00
 -0.00000000e+00  1.55887672e-01  6.21088556e+01  0.00000000e+00
  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.97202098e-01 -0.00000000e+00 -0.00000000e+00
 -0.00000000e+00 -1.67818199e-02  0.00000000e+00 -0.00000000e+00
  0.00000000e+00  5.24373378e-01 -0.00000000e+00  0.00000000e+00
 -0.00000000e+00  8.74408670e-02 -0.00000000e+00  0.00000000e+00
  6.87409944e+01 -0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00
 -0.00000000e+00 -0.00000000e+00  0.00000000e+00  1.14377992e-01
 -2.37058452e-01  1.28608607e+01  0.00000000e+00 -0.00000000e+00]
0.37606756329527613
</pre></div>
</div>
</div>
</div>
<p>Để ý thấy rằng trong hồi qui Lasso thì véc tơ hệ số ước lượng là một véc tơ thưa (<em>sparse vector</em>). Tức là trong các thành phần của nó có số lượng biến khác 0 lớn. Chính nhờ việc giữ lại những biến quan trọng và loại bỏ ảnh hưởng của những biến không quan trọng thông qua triệt tiêu hệ số ước lượng về 0 mà hồi qui <em>Lasso</em> còn là một kĩ thuật quan trọng để lựa chọn biến (<em>feature selection</em>).</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="vi-sao-hoi-qui-lasso-lai-la-hoi-qui-lua-chon-bien">
<h1>2.2.4. Vì sao hồi qui Lasso lại là hồi qui lựa chọn biến<a class="headerlink" href="#vi-sao-hoi-qui-lasso-lai-la-hoi-qui-lua-chon-bien" title="Permalink to this headline">¶</a></h1>
<p>Như vậy chúng ta đã tìm hiểu sơ lược về <em>hồi qui Ridge</em> và <em>hồi qui Lasso</em>. Bây giờ chúng ta sẽ tìm cách giải thích tại sao <em>hồi qui Lasso</em> có thể trả về kết quả là một véc tơ thưa trong khi <em>hồi qui Ridge</em> chỉ tìm cách giảm các hệ số của mô hình chứ không hoàn toàn tiến về 0. Một mô tả được thể hiện thông qua hình bên dưới sẽ giúp ta hiểu rõ hơn.</p>
<p>Giả định rằng tập huấn luyện của chúng ta chỉ có hai đặc trưng. Hình bên dưới sẽ biểu diễn hàm mục tiêu và miền xác định của hai mô hình hồi qui Ridge và Lasso trong không gian hai chiều.</p>
<!-- ![](https://miro.medium.com/max/1400/1*Jd03Hyt2bpEv1r7UijLlpg.png) -->
<p><img alt="" src="https://i.pinimg.com/originals/b8/c1/67/b8c167dcdb3581447c91ef0ac1c67155.png" /></p>
<p>Source: <a class="reference external" href="https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b">Ridge and Lasso Regression</a></p>
<p><strong>Hình 4:</strong> Miền xác định của <em>hồi qui Lasso</em> là <span class="math notranslate nohighlight">\(|\beta_1|+|\beta_2| \leq t\)</span>, trên đồ thị thì miền xác định này là một vùng hình thoi màu xám nằm bên trái. Hình bên phải là <em>hồi qui Ridge</em> có miền xác định được thể hiện bởi một hình tròn màu vàng <span class="math notranslate nohighlight">\(\beta_1^2 + \beta_2^2 \leq C\)</span>. Đồ thị của hàm mục tiêu <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{w})\)</span> được thể hiện qua một tập hợp các đường đồng mức hình ellipse. Mỗi một đường đồng mức sẽ trả về cùng một giá trị hàm mục tiêu. Các đường đồng mức ở gần tâm <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> thì càng có giá trị nhỏ hơn. Khi mở rộng dần đường đồng mức cho tới khi tiệm cận miền xác định chúng ta sẽ thu được nghiệm của bài toán.</p>
<p>Đối với <em>hồi qui Lasso</em> thì thông thường điểm tiếp xúc giữa đường đồng mức của hàm mục tiêu và tập nghiệm thường chạm đỉnh của hình thoi. Đây là những điểm tương ứng với một chiều bằng 0. Trong khi đó, trong <em>hồi qui Ridge</em> thì miền xác định là một hình tròn nên tiểm tiếp xúc sẽ thường có toạ độ khác 0.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="elastic-net">
<h1>2.2.5. Elastic Net<a class="headerlink" href="#elastic-net" title="Permalink to this headline">¶</a></h1>
<p>Hồi qui <em>Elastic Net</em> là một mô hình hồi qui cho phép chúng ta kết hợp đồng thời cả hai thành phần điều chuẩn là norm chuẩn bậc 1 và norm chuẩn bậc 2 theo một kết hợp tuyến tính lồi.</p>
<div class="math notranslate nohighlight">
\[\begin{eqnarray} \mathcal{L}(\mathbf{w}) &amp; = &amp; \frac{1}{N}\|\bar{\mathbf{X}}\mathbf{w} - \mathbf{y}\|_{2}^{2} + \alpha ~[~\lambda \|\mathbf{w}\|_1 + \frac{(1-\lambda)}{2} \|\mathbf{w}\|_2^2~]
\end{eqnarray}\]</div>
<p>Trong phương trình trên thì <span class="math notranslate nohighlight">\(\alpha\)</span> chính là hệ số nhân của <em>thành phần điều chuẩn</em>. <span class="math notranslate nohighlight">\(\lambda\)</span> chính là hệ số nhân của norm chuẩn bậc 1 trong <em>thành phần điều chuẩn</em>. Giá trị của <span class="math notranslate nohighlight">\(0 \leq \lambda \leq 1\)</span>, nếu như <span class="math notranslate nohighlight">\(\lambda = 0\)</span> thì thành phần điều chuẩn hoàn toàn trở thành norm chuẩn bậc 2 và với <span class="math notranslate nohighlight">\(\lambda = 1\)</span> thì bài toán trở thành chuẩn bậc 1. Không có một qui ước cụ thể cho sự lựa chọn tối ưu giữa <span class="math notranslate nohighlight">\(\alpha\)</span> và <span class="math notranslate nohighlight">\(\lambda\)</span> mà chúng ta chỉ có thể đánh giá thông qua tuning.</p>
<p>Để huấn luyện <em>hồi qui Elastic Net</em> trong sklearn chúng ta có thể sử dụng <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">sklearn.linear_model.ElasticNet</span></code>. Các hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> và <span class="math notranslate nohighlight">\(\lambda\)</span> lần lượt tương ứng với <code class="docutils literal notranslate"><span class="pre">alpha</span></code> và <code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code> bên dưới:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>

<span class="n">regr</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 0.23525939  0.          3.36451151  2.31509402  0.24049305  0.0182577
 -1.8341374   1.96160287  2.73396095  1.47473885]
151.96891766544942
</pre></div>
</div>
</div>
</div>
<p>Khi huấn luyện mô hình hồi qui <em>Elastic Net</em> thì làm sao để lựa chọn được cặp hệ số <span class="math notranslate nohighlight">\((\alpha_1, \alpha_2)\)</span> phù hợp? Chúng ta sẽ cùng tìm hiểu về cách thức tuning hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> bên dưới.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tuning-he-so-cho-mo-hinh-hoi-qui-ridge-lasso-va-elastic-net">
<h1>2.2.6. Tuning hệ số cho mô hình hồi qui Ridge, Lasso và Elastic Net<a class="headerlink" href="#tuning-he-so-cho-mo-hinh-hoi-qui-ridge-lasso-va-elastic-net" title="Permalink to this headline">¶</a></h1>
<p>Để tìm ra hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> phù hợp nhất ứng với thành phần điều chuẩn thì chúng ta sẽ thực hiện grid search trên không gian tham số <span class="math notranslate nohighlight">\(\alpha\)</span>. Tiêu chuẩn lựa chọn mô hình sẽ là metric của sai số được đo lường trên <em>tập kiểm tra</em> là nhỏ nhất, thông thường metric này được lựa chọn là <em>MSE</em>. Đồng thời chúng ta cũng cần đối chiếu sai số trên <em>tập kiểm tra</em> với <em>tập huấn luyện</em> để phòng tránh hiện tượng <em>quá khớp</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">PredefinedSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>

<span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">()[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">idx_train</span><span class="p">,</span> <span class="n">idx_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Khởi tạo phân chia tập train/test cho mô hình. Đánh dấu các giá trị thuộc tập train là -1 và tập test là 0</span>
<span class="n">split_index</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_train</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">]</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">PredefinedSplit</span><span class="p">(</span><span class="n">test_fold</span><span class="o">=</span><span class="n">split_index</span><span class="p">)</span>

<span class="c1"># Khởi tạo pipeline gồm 2 bước, &#39;scaler&#39; để chuẩn hoá đầu vào và &#39;model&#39; là bước huấn luyện</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
                     <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                     <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># GridSearch mô hình trên không gian tham số alpha</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span>
                      <span class="p">{</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)},</span> <span class="c1"># Tham số alpha từ 1-&gt;10 huấn luyện mô hình</span>
                      <span class="n">cv</span> <span class="o">=</span> <span class="n">ps</span><span class="p">,</span> <span class="c1"># validation trên tập kiểm tra</span>
                      <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span> <span class="c1"># trung bình tổng bình phương phần dư</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span>
                      <span class="p">)</span>

<span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best core: &#39;</span><span class="p">,</span> <span class="n">search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 1 folds for each of 9 candidates, totalling 9 fits
[CV 1/1] END ................model__alpha=1;, score=-2814.224 total time=   0.0s
[CV 1/1] END ................model__alpha=2;, score=-2814.381 total time=   0.0s
[CV 1/1] END ................model__alpha=3;, score=-2833.032 total time=   0.0s
[CV 1/1] END ................model__alpha=4;, score=-2857.475 total time=   0.0s
[CV 1/1] END ................model__alpha=5;, score=-2886.649 total time=   0.0s
[CV 1/1] END ................model__alpha=6;, score=-2923.552 total time=   0.0s
[CV 1/1] END ................model__alpha=7;, score=-2961.456 total time=   0.0s
[CV 1/1] END ................model__alpha=8;, score=-2985.537 total time=   0.0s
[CV 1/1] END ................model__alpha=9;, score=-3014.196 total time=   0.0s
Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()), (&#39;model&#39;, Lasso(alpha=1))])
Best core:  -2814.2239327473367
</pre></div>
</div>
</div>
</div>
<p>Chúng ta cũng có thể huấn luyện cho nhiều dạng mô hình khác nhau như <code class="docutils literal notranslate"><span class="pre">Ridge,</span> <span class="pre">Lasso,</span> <span class="pre">ElasticNet</span></code>.</p>
<ul class="simple">
<li><p>Đối với mô hình <em>hồi qui Ridge</em>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
                     <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                     <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># GridSearch mô hình trên không gian tham số alpha</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span>
                      <span class="p">{</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">)},</span> <span class="c1"># Tham số alpha từ 1-&gt;10 huấn luyện mô hình</span>
                      <span class="n">cv</span> <span class="o">=</span> <span class="n">ps</span><span class="p">,</span> <span class="c1"># validation trên tập kiểm tra</span>
                      <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span> <span class="c1"># trung bình tổng bình phương phần dư</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span>
                      <span class="p">)</span>

<span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best core: &#39;</span><span class="p">,</span> <span class="n">search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 1 folds for each of 9 candidates, totalling 9 fits
[CV 1/1] END ................model__alpha=1;, score=-2823.056 total time=   0.0s
[CV 1/1] END ................model__alpha=2;, score=-2826.215 total time=   0.0s
[CV 1/1] END ................model__alpha=3;, score=-2828.033 total time=   0.0s
[CV 1/1] END ................model__alpha=4;, score=-2828.995 total time=   0.0s
[CV 1/1] END ................model__alpha=5;, score=-2829.393 total time=   0.0s
[CV 1/1] END ................model__alpha=6;, score=-2829.410 total time=   0.0s
[CV 1/1] END ................model__alpha=7;, score=-2829.162 total time=   0.0s
[CV 1/1] END ................model__alpha=8;, score=-2828.727 total time=   0.0s
[CV 1/1] END ................model__alpha=9;, score=-2828.161 total time=   0.0s
Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()), (&#39;model&#39;, Ridge(alpha=1))])
Best core:  -2823.0556639233228
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Đối với mô hình <em>hồi qui ElasticNet</em>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
                     <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                     <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">ElasticNet</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># GridSearch mô hình trên không gian tham số alpha</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span>
                      <span class="p">{</span>
                          <span class="s1">&#39;model__alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># Tham số alpha</span>
                          <span class="s1">&#39;model__l1_ratio&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span> <span class="c1"># Tham số l1_ratio</span>
                      <span class="p">},</span> <span class="c1"># Tham số alpha từ 1-&gt;10 huấn luyện mô hình</span>
                      <span class="n">cv</span> <span class="o">=</span> <span class="n">ps</span><span class="p">,</span> <span class="c1"># validation trên tập kiểm tra</span>
                      <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span> <span class="c1"># trung bình tổng bình phương phần dư</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span>
                      <span class="p">)</span>

<span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best core: &#39;</span><span class="p">,</span> <span class="n">search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 1 folds for each of 27 candidates, totalling 27 fits
[CV 1/1] END model__alpha=1, model__l1_ratio=0.2;, score=-2962.491 total time=   0.0s
[CV 1/1] END model__alpha=1, model__l1_ratio=0.5;, score=-2872.231 total time=   0.0s
[CV 1/1] END model__alpha=1, model__l1_ratio=0.8;, score=-2813.629 total time=   0.0s
[CV 1/1] END model__alpha=2, model__l1_ratio=0.2;, score=-3250.469 total time=   0.0s
[CV 1/1] END model__alpha=2, model__l1_ratio=0.5;, score=-3064.105 total time=   0.0s
[CV 1/1] END model__alpha=2, model__l1_ratio=0.8;, score=-2874.841 total time=   0.0s
[CV 1/1] END model__alpha=3, model__l1_ratio=0.2;, score=-3503.891 total time=   0.0s
[CV 1/1] END model__alpha=3, model__l1_ratio=0.5;, score=-3265.543 total time=   0.0s
[CV 1/1] END model__alpha=3, model__l1_ratio=0.8;, score=-2974.274 total time=   0.0s
[CV 1/1] END model__alpha=4, model__l1_ratio=0.2;, score=-3716.835 total time=   0.0s
[CV 1/1] END model__alpha=4, model__l1_ratio=0.5;, score=-3450.564 total time=   0.0s
[CV 1/1] END model__alpha=4, model__l1_ratio=0.8;, score=-3085.846 total time=   0.0s
[CV 1/1] END model__alpha=5, model__l1_ratio=0.2;, score=-3897.105 total time=   0.0s
[CV 1/1] END model__alpha=5, model__l1_ratio=0.5;, score=-3619.386 total time=   0.0s
[CV 1/1] END model__alpha=5, model__l1_ratio=0.8;, score=-3200.407 total time=   0.0s
[CV 1/1] END model__alpha=6, model__l1_ratio=0.2;, score=-4050.721 total time=   0.0s
[CV 1/1] END model__alpha=6, model__l1_ratio=0.5;, score=-3770.874 total time=   0.0s
[CV 1/1] END model__alpha=6, model__l1_ratio=0.8;, score=-3316.347 total time=   0.0s
[CV 1/1] END model__alpha=7, model__l1_ratio=0.2;, score=-4182.935 total time=   0.0s
[CV 1/1] END model__alpha=7, model__l1_ratio=0.5;, score=-3907.760 total time=   0.0s
[CV 1/1] END model__alpha=7, model__l1_ratio=0.8;, score=-3430.296 total time=   0.0s
[CV 1/1] END model__alpha=8, model__l1_ratio=0.2;, score=-4297.805 total time=   0.0s
[CV 1/1] END model__alpha=8, model__l1_ratio=0.5;, score=-4030.974 total time=   0.0s
[CV 1/1] END model__alpha=8, model__l1_ratio=0.8;, score=-3536.286 total time=   0.0s
[CV 1/1] END model__alpha=9, model__l1_ratio=0.2;, score=-4398.464 total time=   0.0s
[CV 1/1] END model__alpha=9, model__l1_ratio=0.5;, score=-4142.572 total time=   0.0s
[CV 1/1] END model__alpha=9, model__l1_ratio=0.8;, score=-3640.652 total time=   0.0s
Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;model&#39;, ElasticNet(alpha=1, l1_ratio=0.8))])
Best core:  -2813.6285948414907
</pre></div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tong-ket">
<h1>2.2.7. Tổng kết<a class="headerlink" href="#tong-ket" title="Permalink to this headline">¶</a></h1>
<p>Như vậy qua bài này chúng ta đã được làm quen với lớp các mô hình hồi qui với thành phần điều chuẩn bao gồm <code class="docutils literal notranslate"><span class="pre">Ridge</span> <span class="pre">Regression,</span> <span class="pre">Lasso</span></code> và <code class="docutils literal notranslate"><span class="pre">Elastic</span> <span class="pre">Net</span></code>. Tổng kết lại bài này chúng ta đã biết được rằng:</p>
<ul class="simple">
<li><p>Khi huấn luyện mô hình hồi qui trên bộ dữ liệu có nhiều biến đầu vào (<em>dữ liệu cao chiều</em>) và những biến này có sự tương quan lần nhau thì ước lượng từ mô hình hồi qui tuyến tính thường có phương sai cao dẫn tới hiện tượng <em>quá khớp</em>.</p></li>
<li><p>Để giảm thiểu hiện tượng <em>quá khớp</em>, thông thường sẽ cộng thêm thành phần điều chuẩn vào mô hình hồi qui.</p></li>
<li><p>Có ba kĩ thuật chính để giảm thiểu các hệ số ước lượng từ mô hình hồi qui đó là: <em>Ridge, Lasso</em> và <em>Elastic Net</em>. Trong đó <em>Elastict Net</em> là một kết hợp tuyến tính giữa hồi qui <em>Lasso</em> và <em>Ridge</em>.</p></li>
<li><p>Thành phần điều chuẩn của <em>hồi qui Ridge</em> chính là một trường hợp đặc biệt của điều chuẩn <em>Tikhokov</em>.</p></li>
<li><p>Hồi qui <em>Ridge</em> thì có thành phần điều chuẩn là <span class="math notranslate nohighlight">\(L_2\)</span> trong khi <em>Lasso</em> sử dụng <span class="math notranslate nohighlight">\(L_1\)</span>.</p></li>
<li><p>Phương pháp tuning hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> của các thành phần điều chuẩn thông qua cross-validation để tìm ra mô hình phù hợp nhất.</p></li>
</ul>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="bai-tap">
<h1>2.2.8. Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p>Trong <em>hồi qui Ridge</em> chúng ta sẽ kiểm soát hàm mất mát bằng cách nào?</p></li>
<li><p>Vì sao <em>hồi qui Ridge</em> luôn đảm bảo tìm được giá trị ước lượng cho bài toán tối ưu.</p></li>
<li><p>Theo phương pháp <em>điều chuẩn Tikhokov</em> thì ma trận <span class="math notranslate nohighlight">\(\Gamma\)</span> của <em>thành phần điều chuẩn</em> thường là một ma trận như thế nào?</p></li>
<li><p>Nghiệm của <em>hồi qui Lasso</em> có xu hướng là một véc tơ thưa vì sao?</p></li>
<li><p>Trong <em>hồi qui Elastic Net</em> thì các thành phần điều chuẩn có dạng như thế nào?</p></li>
<li><p>Sử dụng bộ dữ liệu <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston">boston’s house price</a> hãy phân chia tập train/test theo tỷ lệ 80:20. Xây dựng mô hình hồi qui hồi qui tuyến tính dự báo giá nhà trên tập train và đánh giá trên tập test.</p></li>
<li><p>Mô hình có gặp hiện tượng quá khớp hay không? Tìm cách khắc phục hiện tượng quá khớp bằng cách huấn luyện các mô hình hồi qui <em>Ridge, Lasso, ElasticNet</em> với thành phần điều chuẩn.</p></li>
<li><p>Tuning hệ số <span class="math notranslate nohighlight">\(\alpha\)</span> cho từng mô hình để tìm ra mô hình phù hợp nhất trên tập kiểm tra.</p></li>
</ol>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tai-lieu-tham-khao">
<h1>2.2.9. Tài liệu tham khảo<a class="headerlink" href="#tai-lieu-tham-khao" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net">https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net</a></p>
<p><a class="reference external" href="https://machinelearningmastery.com/ridge-regression-with-python/">https://machinelearningmastery.com/ridge-regression-with-python/</a></p>
<p><a class="reference external" href="https://arxiv.org/pdf/1509.09169.pdf">Lecture Note Ridge Regression</a></p>
<p><a class="reference external" href="https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b">https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b</a></p>
<p><a class="reference external" href="https://towardsdatascience.com/ridge-regression-for-better-usage-2f19b3a202db">https://towardsdatascience.com/ridge-regression-for-better-usage-2f19b3a202db</a></p>
<p><a class="reference external" href="https://towardsdatascience.com/bias-variance-and-regularization-in-linear-regression-lasso-ridge-and-elastic-net-8bf81991d0c5">https://towardsdatascience.com/bias-variance-and-regularization-in-linear-regression-lasso-ridge-and-elastic-net-8bf81991d0c5</a></p>
<p><a class="reference external" href="http://www.cs.cmu.edu/~ggordon/10725-F12/slides/08-general-gd.pdf">http://www.cs.cmu.edu/~ggordon/10725-F12/slides/08-general-gd.pdf</a></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index_RidgedRegression.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">2.2. Hồi qui Ridge và Lasso</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="index_classification.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3. Bài toán phân loại</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Pham Dinh Khanh<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>